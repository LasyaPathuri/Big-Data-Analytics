{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Modeling & Analytics - Movie Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PythonMovieRatings\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './ratings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sparkContext.textFile(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_as_list = data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U1,M4,4', 'U1,M4,3', 'U1,M2,5', 'U1,M2,0', 'U1,M3,2', 'U2,M4,3', 'U2,M4,4', 'U2,M4,5', 'U3,M1,1', 'U3,M5,6', 'U3,M4,4', 'U3,M4,5', 'U4,M2,3', 'U4,M1,1', 'U4,M1,4', 'U4,M1,5', 'U5,M1,3', 'U5,M1,1', 'U6,M1,3', 'U6,M9,4']\n"
     ]
    }
   ],
   "source": [
    "print(records_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = data.map(lambda x: (x.split(\",\")[0], x.split(\",\")[1],x.split(\",\")[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Of_Records = rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U1', 'M4', '4'),\n",
       " ('U1', 'M4', '3'),\n",
       " ('U1', 'M2', '5'),\n",
       " ('U1', 'M2', '0'),\n",
       " ('U1', 'M3', '2'),\n",
       " ('U2', 'M4', '3'),\n",
       " ('U2', 'M4', '4'),\n",
       " ('U2', 'M4', '5'),\n",
       " ('U3', 'M1', '1'),\n",
       " ('U3', 'M5', '6'),\n",
       " ('U3', 'M4', '4'),\n",
       " ('U3', 'M4', '5'),\n",
       " ('U4', 'M2', '3'),\n",
       " ('U4', 'M1', '1'),\n",
       " ('U4', 'M1', '4'),\n",
       " ('U4', 'M1', '5'),\n",
       " ('U5', 'M1', '3'),\n",
       " ('U5', 'M1', '1'),\n",
       " ('U6', 'M1', '3'),\n",
       " ('U6', 'M9', '4')]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_Of_Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_after_filtering = rdd.filter(lambda x: (x[2] in ['1','2','3','4','5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U1', 'M4', '4'),\n",
       " ('U1', 'M4', '3'),\n",
       " ('U1', 'M2', '5'),\n",
       " ('U1', 'M3', '2'),\n",
       " ('U2', 'M4', '3'),\n",
       " ('U2', 'M4', '4'),\n",
       " ('U2', 'M4', '5'),\n",
       " ('U3', 'M1', '1'),\n",
       " ('U3', 'M4', '4'),\n",
       " ('U3', 'M4', '5'),\n",
       " ('U4', 'M2', '3'),\n",
       " ('U4', 'M1', '1'),\n",
       " ('U4', 'M1', '4'),\n",
       " ('U4', 'M1', '5'),\n",
       " ('U5', 'M1', '3'),\n",
       " ('U5', 'M1', '1'),\n",
       " ('U6', 'M1', '3'),\n",
       " ('U6', 'M9', '4')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_after_filtering.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_output = records_after_filtering.map(lambda x: (x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M4', 'U1'),\n",
       " ('M4', 'U1'),\n",
       " ('M2', 'U1'),\n",
       " ('M3', 'U1'),\n",
       " ('M4', 'U2'),\n",
       " ('M4', 'U2'),\n",
       " ('M4', 'U2'),\n",
       " ('M1', 'U3'),\n",
       " ('M4', 'U3'),\n",
       " ('M4', 'U3'),\n",
       " ('M2', 'U4'),\n",
       " ('M1', 'U4'),\n",
       " ('M1', 'U4'),\n",
       " ('M1', 'U4'),\n",
       " ('M1', 'U5'),\n",
       " ('M1', 'U5'),\n",
       " ('M1', 'U6'),\n",
       " ('M9', 'U6')]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper_output.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_output = mapper_output.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M4', <pyspark.resultiterable.ResultIterable at 0x256bbb56668>),\n",
       " ('M2', <pyspark.resultiterable.ResultIterable at 0x256bbb4f2b0>),\n",
       " ('M3', <pyspark.resultiterable.ResultIterable at 0x256bbb68588>),\n",
       " ('M1', <pyspark.resultiterable.ResultIterable at 0x256bbb68208>),\n",
       " ('M9', <pyspark.resultiterable.ResultIterable at 0x256bbb684a8>)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_output.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_key_values = grouped_output.map(lambda x: (x[0], list(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M4', ['U1', 'U1', 'U2', 'U2', 'U2', 'U3', 'U3']),\n",
       " ('M2', ['U1', 'U4']),\n",
       " ('M3', ['U1']),\n",
       " ('M1', ['U3', 'U4', 'U4', 'U4', 'U5', 'U5', 'U6']),\n",
       " ('M9', ['U6'])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_key_values.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_result = grouped_key_values.map(lambda x: (x[0], (np.size(np.asarray(x[1])),np.size(np.unique(np.asarray(x[1]))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M4', (7, 3)),\n",
       " ('M2', (2, 2)),\n",
       " ('M3', (1, 1)),\n",
       " ('M1', (7, 4)),\n",
       " ('M9', (1, 1))]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducer_result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reducer_result = reducer_result.filter(lambda x: (x[1][1] >= 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M4', (7, 3)), ('M2', (2, 2)), ('M1', (7, 4))]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reducer_result.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
